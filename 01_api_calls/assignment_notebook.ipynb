{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi7xzykjgGP9"
      },
      "source": [
        "## Lab 1: Getting data from API's\n",
        "\n",
        "A great source of data and Pandas practice is getting data from the Internet. It is not going to come in a .csv file, though: It will be a stream of records, typically in XML (eXtensible Mark-up Language) or JSON (JavaScript Object Notation) format.\n",
        "\n",
        "We'll look at a very simple API and some useful code chunks for getting and analyzing data, and then you'll take a look at the APIs available from the Federal government as the main work for your lab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko09F0g3gGP-"
      },
      "source": [
        "## API Queries\n",
        "\n",
        "The core programming skill of the activity is to learn to query an online Application Programmer Interface (API). It is a similar experience to browsing the Internet, and initial results can be displayed the web browser. When visiting a web page, the address bar typically contains something like\n",
        "$$\n",
        "\\texttt{https://} \\underbrace{\\texttt{www.}}_{\\text{World Wide Web subdomain}} \\texttt{domain}. \\underbrace{\\texttt{tld}}_{\\text{Top level domain}},\n",
        "$$\n",
        "where the https:// specifies the protocol, www. specifies the world-wide-web subdomain, the domain is the entity, and the top-level domain .tld is typically something like .com or .gov, but is increasingly varied as ICANN releases more TLD's into circulation.\n",
        "\n",
        "With an online API, the user instead enters a url that goes directly to an API subdomain\n",
        "$$\n",
        "\\texttt{https://} \\underbrace{\\texttt{api.}}_{\\text{Application programmer interface}} \\texttt{domain.tld}/ \\texttt{(the query)}\n",
        "$$\n",
        "or accesses REST services as\n",
        "$$\n",
        "\\texttt{https://www.domain.tld} \\underbrace{\\texttt{/REST}}_{\\text{Accesses REST services}}/ \\texttt{(the query)}\n",
        "$$\n",
        "This accesses data on the domain's servers and returns the result directly to the user.\n",
        "\n",
        "The query itself is typically a string beginning with a question mark ?, followed by a series of expressions joined by ampersands &. For example,\n",
        "\n",
        "`?ProductType=Phone\\&Manufacturer=Apple`\n",
        "\n",
        "passes a query requesting all records for which the product type is recorded as phone and the manufacturer is recorded as Apple. Some API's include date ranges and other, more complex requests.\n",
        "\n",
        "To get started, a simple warm-up is to use the API from saferproducts.gov, which has a simple and intuitive structure for queries, and the results are simple enough to look at in the browser. Typing this in the address bar in a browser should yield about thirty records:\n",
        "\n",
        "    https://www.saferproducts.gov/RestWebServices/Recall?format=json&ProductType=Phone  \n",
        "\n",
        "with the first being, on this occasion:\n",
        "\n",
        "    \"RecallID\": 7856,\n",
        "    \"RecallNumber\": \"16266\",\n",
        "    \"RecallDate\": \"2016-09-15T00:00:00\",\n",
        "    \"Description\": \"This recall involves the Samsung Galaxy Note7 smartphone sold before\n",
        "    September 15, 2016. The recalled devices have a 5.7 inch screen and were sold in the\n",
        "    following colors: black onyx, blue coral, gold platinum and silver titanium with a\n",
        "    matching stylus. Samsung is printed on the top front of the phone and Galaxy Note7\n",
        "    is printed on the back of the phone. To determine if your phone has been recalled,\n",
        "    locate the IMEI number on the back of the phone or the packaging, and enter the IMEI\n",
        "    number into the online registration site www.samsung.com or call Samsung toll-free\n",
        "    at 844-365-6197.\",\n",
        "    \"URL\": \"https://www.cpsc.gov/Recalls/2016/Samsung-Recalls-Galaxy-Note7-Smartphones\",\n",
        "    \"Title\": \"Samsung Recalls Galaxy Note7 Smartphones Due to Serious Fire and Burn Hazards\",\n",
        "    \"ConsumerContact\": \"Contact your wireless carrier or place of purchase, call Samsung\n",
        "    toll-free at 844-365-6197 anytime, or go online at www.samsung.com.\",\n",
        "    \"LastPublishDate\": \"2016-10-27T00:00:00\"\n",
        "\n",
        "The query itself in this case is:\n",
        "\n",
        "    ?format=json&ProductType=Phone  \n",
        "\n",
        "The quert requests all of the recalls in JavaScript Object Notation (json) format, where the `ProductType` variable is equal to `Phone`. In addition to `ProductType`, other options include:\n",
        "\n",
        "    RecallID,\n",
        "    RecallNumber,\n",
        "    RecallDateStart,\n",
        "    RecallDateEnd,\n",
        "    RecallURL,\n",
        "    LastPublishDateStart,\n",
        "    LastPublishDateEnd,\n",
        "    RecallTitle,\n",
        "    ConsumerContact,\n",
        "    RecallDescription,\n",
        "    ProductName,\n",
        "    ProductDescription,\n",
        "    ProductModel,\n",
        "    ProductType,\n",
        "    InconjunctionURL,\n",
        "    ImageURL,\n",
        "    Injury,\n",
        "    Manufacturer,\n",
        "    Retailer,\n",
        "    Importer,\n",
        "    Distributor,\n",
        "    ManufacturerCountry,\n",
        "    UPC,\n",
        "    Hazard,\n",
        "    Remedy,\n",
        "    RemedyOption\n",
        "\n",
        "**1. Practice writing queries using the saferproducts.gov API and your web browser.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zwfi6ndgGP-"
      },
      "source": [
        "## Accessing API's with Python\n",
        "\n",
        "Anytime you use a computer to access resources on the Internet, you will likely run into problems. There are many options, but two with low coding overhead: The `requests` and `urrlib.requests` packages.\n",
        "\n",
        "The following code chunk uses the `requests` package to get the same kind of data that was being displayed in the browser, but in an interactive Python session:\n",
        "\n",
        "    import requests\n",
        "    url = 'https://www.saferproducts.gov/RestWebServices/' # Location of the API\n",
        "    query = 'Recall?format=json&ProductType=Exercise' # The query\n",
        "    header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0)\n",
        "        Gecko/20100101 Firefox/124.0'} # The user-agent to avoid being blocked\n",
        "    raw = requests.get(url+query,headers=header) # Query the database\n",
        "    data = raw.json() # Convert data from json to dictionary\n",
        "\n",
        "To make the code easier to read, it separates the url and the query into two different strings, then concatenates them in the GET request. This makes it easier to edit the query, as well as suggests a simple way to loop over a number of queries that might be sent to the same API.\n",
        "\n",
        "Many resources are designed to block access from particular kinds of users. In order to circumvent these obstacles, you can specify a `header` dictionary that presents the query to the server as coming from a hypothetical and common user. In this case, the header presents the query as coming from a Firefox browser from a Windows computer, rather than something like `python-requests/3.12.1`. This problem appears generally in scraping data from the web, and can grind the process to a halt. For whatever reason, I have been blocked and gotten 403 errors with the `requests` package, which motivated me to prepare a second alternative that seems more robust:\n",
        "\n",
        "    import urllib.request\n",
        "    import json\n",
        "    url = 'https://www.saferproducts.gov/RestWebServices/' # Location of the API\n",
        "    query = 'Recall?format=json&ProductType=Exercise' # The query\n",
        "    response = urllib.request.urlopen(url+query)\n",
        "    response_bytes = response.read()\n",
        "    data = json.loads(response_bytes) # Convert response to json\n",
        "    response.close()\n",
        "\n",
        "This is a bit more code and some steps are a bit less human-friendly, but seems to work a bit more reliably than `requests`.\n",
        "\n",
        "**2. Practice with the saferproducts.gov API and the above code in a notebook to see how API's work, in general.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import urllib.request\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = 'https://www.saferproducts.gov/RestWebServices/'\n",
        "query = 'Recall?format=json&ProductType=Phone'\n",
        "response = urllib.request.urlopen(url+query)\n",
        "response_bytes = response.read()\n",
        "data = json.loads(response_bytes)\n",
        "response.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWk9ceyRgGP_"
      },
      "source": [
        "## Wrangling the Data\n",
        "\n",
        "Piping the data to Pandas is easy, because the preceding code chunk put the JSON data into a native Python dictionary, and the following converts it to a dataframe:\n",
        "\n",
        "    df = pd.DataFrame.from_dict(data)\n",
        "\n",
        "If the data is in raw XML or JSON format --- which might especially be true with other API's --- it would instead be \\texttt{pd.read\\_xml(data)} or \\texttt{pd.read\\_json(data)}. Ironing out these details in advance for other applications is a key part of the presentation for students, but having students resolve these issues as a component of group work or an assignment is a great way to help them mature as coding problem solvers by struggling with documentation and a well-defined problem.\n",
        "\n",
        "Unfortunately, there aren't many non-text fields in the \\texttt{www.saferproducts.gov} data. However, there are a few fields of interest that can be tabulated and discussed, such as RemedyOptions and ManufacturerCountries:\n",
        "\n",
        "    df['RemedyOptions'].value_counts()\n",
        "\n",
        "with output\n",
        "\n",
        "    RemedyOptions\n",
        "    []                                                                               139\n",
        "    [{'Option': 'Repair'}]                                                            49\n",
        "    [{'Option': 'Replace'}]                                                           12\n",
        "    [{'Option': 'Refund'}]                                                             7\n",
        "    [{'Option': 'Replace'}, {'Option': 'Repair'}]                                      4\n",
        "    [{'Option': 'Refund'}, {'Option': 'Replace'}, {'Option': 'Repair'}]                1\n",
        "    [{'Option': 'Replace'}, {'Option': 'Refund'}]                                      1\n",
        "    [{'Option': 'Refund'}, {'Option': 'Repair'}]                                       1\n",
        "    [{'Option': 'Label'}]                                                              1\n",
        "    [{'Option': 'New Instructions'}, {'Option': 'Replace'}, {'Option': 'Refund'}]      1\n",
        "    Name: count, dtype: int64\n",
        "\n",
        "It's appropriate at this point to do some data cleaning, particularly by flattening dictionary entries. With response data that get converted from json to a dictionary, there are often values in the data frame that need to be flattened or unpacked. For example, some values are recorded as \\texttt{ [$\\{$'Country':'Canada'$\\}$]}, or, worse, a dictionary with multiple entries: \\texttt{[ $\\{$ 'Option': 'Replace'$\\}$, $\\{$'Option': 'Repair'$\\}$]  ] }. This can lead to problems when another package refuses to work with a lists of lists or doesn't know how to simplify a dictionary to data, and presents some conceptual questions when cleaning.\n",
        "\n",
        "A simple script to recursively collapse the dictionary entries into a single string is:\n",
        "\n",
        "    temp = df['RemedyOptions']\n",
        "    clean_values = []\n",
        "    for i in range(len(temp)):\n",
        "        if len(temp[i])>0:\n",
        "            values = []\n",
        "            for j in range(len(temp[i])):\n",
        "                values.append(temp[i][j]['Option'] )\n",
        "            clean_values.append(values)\n",
        "        else:\n",
        "            clean_values.append('')\n",
        "    df['remedy'] = clean_values\n",
        "\n",
        "**3. Convert this code chunk into a function you can reuse to flatten dictionaries, or explain clearly the problems you run into while attempting to do so. Make some tables or plots.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          RecallID\n",
            "count    29.000000\n",
            "mean   4331.793103\n",
            "std    1461.728194\n",
            "min    1158.000000\n",
            "25%    3215.000000\n",
            "50%    4594.000000\n",
            "75%    5364.000000\n",
            "max    7856.000000 \n",
            "\n",
            "[{'Name': 'Choking', 'HazardType': '', 'HazardTypeID': ''}]                                                                                                                                                                                             10\n",
            "[{'Name': 'Burn - Not Fire-Related', 'HazardType': '', 'HazardTypeID': ''}]                                                                                                                                                                              4\n",
            "[{'Name': 'Fire & Fire-Related Burn', 'HazardType': '', 'HazardTypeID': ''}]                                                                                                                                                                             3\n",
            "[{'Name': 'The lithium-ion battery in the Galaxy Note7 smartphones can overheat and catch fire, posing a serious burn hazard to consumers.', 'HazardType': '', 'HazardTypeID': ''}]                                                                      1\n",
            "[{'Name': 'A mirror decal attached to the toy can peel away, posing a potential choking hazard.', 'HazardType': '', 'HazardTypeID': ''}]                                                                                                                 1\n",
            "[{'Name': 'The recalled cell phones that are in a no-service area and display an \"out of range, try again later\" message could fail to connect to emergency 911.', 'HazardType': '', 'HazardTypeID': ''}]                                                1\n",
            "[{'Name': 'The recalled phones can have difficulty sustaining a connection or have poor voice quality on calls to emergency 911.', 'HazardType': '', 'HazardTypeID': ''}]                                                                                1\n",
            "[{'Name': 'The battery packs can overheat, posing a fire or burn hazard.', 'HazardType': '', 'HazardTypeID': ''}]                                                                                                                                        1\n",
            "[{'Name': 'The hinge cover on the toy cell phone can detach from the phone, posing a choking hazard to young children.', 'HazardType': '', 'HazardTypeID': ''}]                                                                                          1\n",
            "[{'Name': 'A software problem with the cell phones causes audio problems with 911 calls. When a call is connected to 911, the operator may not hear the caller or the caller may not hear the 911 operator.', 'HazardType': '', 'HazardTypeID': ''}]     1\n",
            "[{'Name': 'The metal pin inside the hinge of the cell phone flip-top can fall out, posing a choking hazard to young children.', 'HazardType': '', 'HazardTypeID': ''}]                                                                                   1\n",
            "[{'Name': 'The push buttons on the toy phone can detach, posing a choking hazard to young children.', 'HazardType': '', 'HazardTypeID': ''}]                                                                                                             1\n",
            "[{'Name': 'The toy phone's yellow antenna can detach, posing a choking hazard to young children. No injuries have been reported.', 'HazardType': '', 'HazardTypeID': ''}]                                                                                1\n",
            "[{'Name': 'Electrocution/Electric Shock', 'HazardType': '', 'HazardTypeID': ''}]                                                                                                                                                                         1\n",
            "[{'Name': 'Laceration', 'HazardType': '', 'HazardTypeID': ''}]                                                                                                                                                                                           1\n",
            "Name: Hazards, dtype: int64 \n",
            "\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "unhashable type: 'list'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[45], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(df.value_counts()) Why does this throw an unhashable type 'list' error?\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHazards\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts(),\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mManufacturerCountries\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcount())\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:2070\u001b[0m, in \u001b[0;36mGroupBy.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2062\u001b[0m \u001b[38;5;124;03mCompute count of group, excluding missing values.\u001b[39;00m\n\u001b[1;32m   2063\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;124;03m    Count of values within each group.\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_to_aggregate()\n\u001b[0;32m-> 2070\u001b[0m ids, _, ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mgroup_info\n\u001b[1;32m   2071\u001b[0m mask \u001b[38;5;241m=\u001b[39m ids \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2073\u001b[0m is_series \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:946\u001b[0m, in \u001b[0;36mBaseGrouper.group_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgroup_info\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m--> 946\u001b[0m     comp_ids, obs_group_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_compressed_codes()\n\u001b[1;32m    948\u001b[0m     ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs_group_ids)\n\u001b[1;32m    949\u001b[0m     comp_ids \u001b[38;5;241m=\u001b[39m ensure_platform_int(comp_ids)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:977\u001b[0m, in \u001b[0;36mBaseGrouper._get_compressed_codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# FIXME: compress_group_index's second return value is int64, not intp\u001b[39;00m\n\u001b[1;32m    976\u001b[0m ping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ping\u001b[38;5;241m.\u001b[39mcodes, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(ping\u001b[38;5;241m.\u001b[39mgroup_index), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:621\u001b[0m, in \u001b[0;36mGrouping.codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;66;03m# _codes is set in __init__ for MultiIndex cases\u001b[39;00m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes\n\u001b[0;32m--> 621\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes_and_uniques[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:692\u001b[0m, in \u001b[0;36mGrouping._codes_and_uniques\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    685\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    686\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouping_vector\u001b[38;5;241m.\u001b[39mresult_index\u001b[38;5;241m.\u001b[39m_values  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     )\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# GH35667, replace dropna=False with use_na_sentinel=False\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Union[\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any], Index]\", variable has type \"Categorical\")\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m algorithms\u001b[38;5;241m.\u001b[39mfactorize(  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouping_vector, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort, use_na_sentinel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dropna\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/algorithms.py:822\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, use_na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[1;32m    820\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[0;32m--> 822\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[1;32m    823\u001b[0m         values,\n\u001b[1;32m    824\u001b[0m         na_sentinel\u001b[38;5;241m=\u001b[39mna_sentinel_arg,\n\u001b[1;32m    825\u001b[0m         size_hint\u001b[38;5;241m=\u001b[39msize_hint,\n\u001b[1;32m    826\u001b[0m     )\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m na_sentinel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    830\u001b[0m         \u001b[38;5;66;03m# TODO: Can remove when na_sentinel=na_sentinel as in TODO above\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/algorithms.py:578\u001b[0m, in \u001b[0;36mfactorize_array\u001b[0;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    575\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[1;32m    577\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[0;32m--> 578\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfactorize(\n\u001b[1;32m    579\u001b[0m     values,\n\u001b[1;32m    580\u001b[0m     na_sentinel\u001b[38;5;241m=\u001b[39mna_sentinel,\n\u001b[1;32m    581\u001b[0m     na_value\u001b[38;5;241m=\u001b[39mna_value,\n\u001b[1;32m    582\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m    583\u001b[0m     ignore_na\u001b[38;5;241m=\u001b[39mignore_na,\n\u001b[1;32m    584\u001b[0m )\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[1;32m    587\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5943\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5857\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ],
      "source": [
        "def flatten(d,key):\n",
        "    clean = []\n",
        "    for i in range(len(d)):\n",
        "        l = len(d[i])\n",
        "        if l > 0:\n",
        "            x = []\n",
        "            for j in range(l):\n",
        "                x.append(d[i][j][key])\n",
        "            clean.append(x)\n",
        "        else:\n",
        "            clean.append('')\n",
        "    return clean\n",
        "# This gave me trouble because I didn't realize each column had a different dictionary key\n",
        "df = pd.DataFrame.from_dict(data)\n",
        "df['RemedyOptions'] = flatten(df['RemedyOptions'],'Option')\n",
        "df['Products'] = flatten(df['Products'],'Name')\n",
        "df[\"ManufacturerCountries\"] = flatten(df['ManufacturerCountries'],'Country')\n",
        "\n",
        "print(df.describe(),'\\n')\n",
        "# print(df.value_counts()) Why does this throw an unhashable type 'list' error?\n",
        "print(df['Hazards'].value_counts(),'\\n')\n",
        "# print(df.groupby(['ManufacturerCountries']).count()) Unhashable type error here as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glTQ8P7ggGP_"
      },
      "source": [
        "## Dashboarding the Results (Optional)\n",
        "\n",
        "To complete the pipeline from data to product, we can use \\texttt{streamlit} to quickly convert Python code into a web page that can be accessed locally. This can be done with essentially three lines of code: An import statement, a $.title()$ method call to set the page title, and an $.write()$ call to push the results to the page. Although relatively static, completing this step serves a pedogogical and psychological purpose: It pivots the students to thinking about how to communicate results to an audience, and how the project could become an ongoing endeavor rather than a single analytical exercise.\n",
        "\n",
        "The entire .py file to create the dashboard is\n",
        "\n",
        "    import pandas as pd\n",
        "    import requests\n",
        "    import streamlit as st\n",
        "    # Conduct analysis:\n",
        "    url = 'https://www.saferproducts.gov/RestWebServices/Recall'\n",
        "    query = '?format=json&RecallTitle=Gas'\n",
        "    header = {'User-Agent':\n",
        "              'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0'}\n",
        "    raw = requests.get(url+query,headers=header)\n",
        "    data = raw.json()\n",
        "    df = pd.DataFrame.from_dict(data)\n",
        "    temp = df['RemedyOptions']\n",
        "    clean_values = []\n",
        "    for i in range(len(temp)):\n",
        "        if len(temp[i])>0:\n",
        "            values = []\n",
        "            for j in range(len(temp[i])):\n",
        "                values.append(temp[i][j]['Option'] )\n",
        "            clean_values.append(values)\n",
        "        else:\n",
        "            clean_values.append('')\n",
        "    df['remedy'] = clean_values\n",
        "    remedy_counts = df['remedy'].value_counts()\n",
        "    # Create streamlit output:\n",
        "    st.title('Remedy Statistics')\n",
        "    st.write(remedy_counts)\n",
        "\n",
        "To create the web page, run the following at the command line:\n",
        "\n",
        "    streamlit run remedy.py\n",
        "\n",
        "This should convert the above analysis into a web page available from localhost.\n",
        "\n",
        "**4. Produce your own table or plot, and output it to streamlit.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ogbrOZYgGP_"
      },
      "source": [
        "## Other API Sources\n",
        "\n",
        "Valuable and interesting Federal API resources are listed at:\n",
        "\n",
        "    https://catalog.data.gov/dataset/?_res_format_limit=0&res_format=API\n",
        "\n",
        "and in the future will likely easily be found at \\texttt{data.gov}. Some highlights include:\n",
        "\n",
        "- CDC WONDER API for Data Query Web Service: Includes death certificates with causes since approximately the 1990's.\n",
        "- Comprehensive Housing Affordability Strategy (CHAS): Housing and Urban Development (HUD) maintains an API that provides Census data on housing problems and needs unavailable through other sources, including IPUMS.\n",
        "- Federal Election Commission API: Provides historical and up to the minute campaign finance data.\n",
        "- Toxic Release Inventory: Provided by the Environmental Protection Agency, this API documents the release and management of over 800 toxic substances, reported annually by privately owned facilities and the government.\n",
        "- Petroleum Data, Prices: Provides prices of petroleum products and crude oil at weekly, monthly, and yearly time scales.\n",
        "- Fair Market Rents Lookup tool: Fair Market Rents (FMRs) determine the value of housing vouchers for Section 8 renters. This API provides the FMR values and other measures of housing affordability.\n",
        "- Annual Economic Surveys, Business Patterns: Surveys of businesses at the zip code level, tracking economic sentiment and activity.\n",
        "- Food Access Research Atlas: Provides spatial data on food access and the availability of supermarkets within census tracts. Can be merged with census data to look at under-served populations and food deserts.\n",
        "- National Oceanographic and Atmospheric Administration: Provides API access to data on real time weather and climate change projections.\n",
        "\n",
        "Each of these API resources could either be the cornerstone of a project or a source of additional data. These data sources have a number of advantages: They're free, most of them can be accessed using the same API key, and most have similar documentation for how to write a query. This is ideal for students to iterate, experiment, and take risks, with little cost to failure.\n",
        "\n",
        "In addition to government data, many commerical apps provide API access to developers and researchers. AirBnB, Amazon, Reddit, eBay, X, and many others maintain API access to develop third-party apps. These opportunities present many advantages: The data are larger, have more variety, and there are vastly many more cases. Building a third-party app that includes analytics could easily consume an entire semester and open a variety of applications in predictive analytics, natural language processing, and generative AI (e.g. predict which reviews are fake or real for Amazon for a product group like ``women's watches', and then make recommendations for different price points). While an exciting possibility, this can also raise a lot of problems: Some API's cost money or are rate-limited depending on a subscription, and others impose significant constraints on how the data can be used. In some cases, a more useful approach might be explicit web scraping using a package like BeautifulSoup or Selenium. For example, Craigslist has no API, but can easily and productively be scraped using BeautifulSoup.\n",
        "\n",
        "**5. Pick an API, download some data, wrangle them, and produce some EDA results, as we did in the previous steps with the saferproducts.gov API; or, if you can't get it to work, document why. If you have the time and it's low cost, push the results to a streamlit page. If you have had enough, I recommend https://www.eia.gov/opendata/browser/electricity, since there is a friendly query builder that you can use to learn.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import urllib.request\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "url = 'https://api.eia.gov/v2/co2-emissions/co2-emissions-aggregates/data?' # Location of the API\n",
        "key = 'api_key=UXLEWgt9NnP4HvOz4Mlf19LpR23Q4r7RUW3wxEvh'\n",
        "query = '&frequency=annual&data[0]=value&start=1970&end=2021&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=5000'\n",
        "# header = { \"frequency\": \"annual\",\n",
        "#     \"data\": [\n",
        "#         \"value\"\n",
        "#     ],\n",
        "#     \"facets\": {},\n",
        "#     \"start\": \"1970\",\n",
        "#     \"end\": '2021',\n",
        "#     \"sort\": [\n",
        "#         {\n",
        "#             \"column\": \"period\",\n",
        "#             \"direction\": \"desc\"\n",
        "#         }\n",
        "#     ],\n",
        "#     \"offset\": 0,\n",
        "#     \"length\": 5000}\n",
        "# raw = requests.get(url+query,headers=header)\n",
        "# data = raw.json()\n",
        "response = urllib.request.urlopen(url+key+query)\n",
        "response_bytes = response.read()\n",
        "data = json.loads(response_bytes) # Convert response to json\n",
        "response.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[82], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m'\u001b[39m],errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2021\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal CO2 in 2021: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mfilter\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m million metric tons of CO2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame.from_dict(data)\n",
        "df = df['response']['data']\n",
        "df = pd.DataFrame(df)\n",
        "\n",
        "# sns.countplot(df['period'].iloc[0,1248],x='fuel-name')\n",
        "df['period'] = pd.to_numeric(df['period'],errors='coerce')\n",
        "filter = df[df['period']==2021]\n",
        "print(\"Total CO2 in 2021: \" + str(sum(filter['value'])) + \" million metric tons of CO2\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
